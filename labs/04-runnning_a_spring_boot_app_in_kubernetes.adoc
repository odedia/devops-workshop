= 04. Deploying to Kubernetes
In this lab we'll deploy our very simple application to Kubernetes, and try to make it production ready.

Login to PKS cluster shared by the instructor.

== Creating a namespace

Create a new namespace for your team:

[source,bash]
---------------------------------------------------------------------
kubectl create namespace <my-team>
---------------------------------------------------------------------


== Creating a deployment

Create a deployment manifest to run the image we just deployed. Here's a skeleton you can use (or write your own):

[source,yml]
---------------------------------------------------------------------
apiVersion: extensions/v1beta1
kind: Deployment
metadata:
  annotations:
    deployment.kubernetes.io/revision: "1"
  labels:
    run:
  name:
  namespace: default
spec:
  replicas:
  selector:
    matchLabels:
      run:
  strategy:
    rollingUpdate:
      maxSurge:
      maxUnavailable:
    type:
  template:
    metadata:
      labels:
        run:
    spec:
      containers:
      - image:
        imagePullPolicy:
        name:
        ports:
        - containerPort:
          protocol:
      dnsPolicy:
      restartPolicy:
---------------------------------------------------------------------

== Creating a service

Since we're using PKS, we're lucky - we can use a `LoadBalancer`. If we were to use another solution we might have to revert to a `NodePort` or to implement other solutions.
Complete the skeleton yaml below, or write your own:

[source,yml]
---------------------------------------------------------------------
apiVersion: v1
kind: Service
metadata:
  labels:
    run:
  name:
  namespace:
spec:
  ports:
  - nodePort:
    port:
    protocol:
    targetPort:
  selector:
    run:
  sessionAffinity: None
  type:
---------------------------------------------------------------------

== Exposing a DNS Record

There are several ways to expose the service as a routable URL:

. You can create an A record pointing to the load balancer. You will have to make sure the IP doesn't change.
+
-> Problem: Developers rarely have access to DNS, which means waiting for tickets between development and IT.
. You can create an ingress gateway that routes to the deployment, which requires installing an additional ingress service to the cluster such as nginx.
. You can leverage Istio/KNative

For now, let's just use the External IP we got.

== Scaling

Edit the deployment yaml so that there are 3 pods instead of 1.

== Testing our results

Check your external IP by running:

[source,bash]
---------------------------------------------------------------------
kubectl get svc -n <my-team-namespace>
---------------------------------------------------------------------

Open http://<my-external-ip>/hello and make sure you got a response.

== Making changes

One of the main advantages of going cloud-native is to have a fast feedback loop.
What would happen if you were to make a single change in the code right now?

. Change the greeting message from "Hello World!" to "Hello VMware!".
. Get your new code to a running state in Kubernetes.

== Logging

Check the logs of one of the pods by running `kubectl logs <pod-name> -n <my-team-namespace>`.

Logs from one pod is nice, but your application is being served from multiple pods.
How can you get the logs from all pods of your app?

. You can use sidecar containers to manually handle logging to a central solution
. You can install Fluentd daemon sets (requires privilege access to `kube_system` namespace)
. You can use commercial solutions such as Splunk, Datadog, SumoLogic, Log Insight etc. (at an added cost)
. You can use open source solutions such as ELK, Graylog (but it is now your responsibility to maintain and upgrade this solution)

== Monitoring

Our container provides basic metric information. We can get some of the data by running:

[source,bash]
---------------------------------------------------------------------
kubectl describe pod <my-pod> -n <my-team-namespace>
---------------------------------------------------------------------

But this will only give us information on a specific pod. What about connections between pods or deployments?
How can we find our own metrics that we expose via actuator? We can query the _/actuator_ URL but this will only give a response from _one_ of the pods.

. You can use commercial solutions such as SysDig, Dynatrace, NewRelic, Wavefront (at an added cost)
. You can use open source solutions such as Kibana, Prometheus, Grafana (but it is your responsibility to maintain and upgrade them)

== The bottom line: If you got all of the requirements above working well, congradulations - you built your own platform on top of Kubernetes!

image::images/k8s1.jpg[]
image::images/k8s2.jpg[]
image::images/k8s3.jpg[]
